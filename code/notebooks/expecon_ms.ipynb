{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bea27a-d056-440b-b0ac-77393b47c418",
   "metadata": {},
   "source": [
    "# python code for results from Forster et al., 2024 (unpublished)\n",
    "\n",
    "running title: \"Prestimulus beta power encodes somatosensory stimulus expectations\"\n",
    "\n",
    "notebook loads functions for behavioral and EEG analysis and reproduces figure 1,2,3 and 4\n",
    "\n",
    "figure 5 and 6 are based on Rscripts, which are used for regression and mediation analysis\n",
    "\n",
    "results are published in Forster et al. (*in prep*)\n",
    "___\n",
    "\n",
    "    Author:  Carina Forster et al.\n",
    "    Contact: forster@cbs.mpg.de\n",
    "    Years:   2023\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fbe856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Make sure you are in the right environment: `expecon_3.9`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a1546-d4d0-4e6c-97f0-32c5f16ab141",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6819468-c507-4884-8d73-cf4c4aa7f99e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warnings for a cleaner output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7906a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6704887",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# import functions for behavioral analysis\n",
    "from expecon_ms.behav import figure1 as behav\n",
    "\n",
    "# expecon_ms functions\n",
    "from expecon_ms.configs import config, params, paths\n",
    "from expecon_ms.eeg.preprocessing import ica\n",
    "\n",
    "# Import functions from expecon_package for preproccesing eeg data\n",
    "from expecon_ms.eeg.preprocessing import prepro as pp\n",
    "\n",
    "# import functions for EEG analysis and visualization\n",
    "from expecon_ms.eeg.sensor import evokeds as evo\n",
    "from expecon_ms.eeg.sensor import tfr_contrasts as tfr\n",
    "\n",
    "# import functions for source analysis\n",
    "from expecon_ms.eeg.source import source_reco\n",
    "from expecon_ms.eeg.source import plot_source_behav_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e868dd-0b21-45dc-83e7-88d075caff73",
   "metadata": {},
   "source": [
    "### Set vars, paths, & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output for mne functions\n",
    "mne.set_log_level(\"CRITICAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1579d-4481-4ee5-9b9f-8ed9d5871cfa",
   "metadata": {},
   "source": [
    "## Analyse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a2789",
   "metadata": {},
   "source": [
    "### 1. Behavioral data analysis (Signal detection theory based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the function arguments the docs\n",
    "help(behav.plot_figure1_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fccbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "behav.plot_figure1_grid(expecon=1, exclude_high_fa=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dec5cc",
   "metadata": {},
   "source": [
    "### 2. Preprocessing EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d686dec-24e9-4d4b-9820-853e883f319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function expects a raw object with .fif file ending\n",
    "pp.prepro(\n",
    "    study=2,\n",
    "    trigger=\"stimulus\",\n",
    "    l_freq=1,\n",
    "    h_freq=40,\n",
    "    tmin=-1,\n",
    "    tmax=1,\n",
    "    resample_rate=250,\n",
    "    sf=2500,\n",
    "    detrend=1,\n",
    "    ransac=1,\n",
    "    autoreject=0,\n",
    ")\n",
    "\n",
    "# how many channels were interpolated?\n",
    "pp.n_channels_interpolated(study=2, trigger=\"stimulus\", l_freq=0.1)\n",
    "\n",
    "# run ica on clean, epoched data\n",
    "ica.run_ica(study=2, infomax=1, save_psd=1)\n",
    "# correlate with EOG and ECG and mark bad componets for rejection\n",
    "\n",
    "ica.label_ica_correlation(study=2)\n",
    "\n",
    "# usa icalabel to mark components for rejection\n",
    "# ica.label_iclabel(study=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75804a8a",
   "metadata": {},
   "source": [
    "#### ICA stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which study to run the analysis on\n",
    "study = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file that contains the number of components rejected\n",
    "df_comp = pd.read_csv(\n",
    "    Path(\"E:/expecon_ms/data/eeg/prepro_ica/clean_epochs_corr{study!s}/ica_components_stats_icacorr.csv\")\n",
    ")\n",
    "\n",
    "# mean components rejected\n",
    "print(f' on average {df_comp[\"0\"].mean()} components were rejected')\n",
    "print(f' the sdt of components rejected is {df_comp[\"0\"].std()}')\n",
    "print(f' the maximum of components rejected is {df_comp[\"0\"].max()}')\n",
    "print(f' the minimum of components rejected is {df_comp[\"0\"].min()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12612fd5",
   "metadata": {},
   "source": [
    "### 3. Evoked potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare evokeds and plot contrasts\n",
    "evokeds = evo.create_contrast(\n",
    "    study=2, drop_bads=True, laplace=False, subtract_evoked=False, save_data_to_disk=False, save_drop_log=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26895e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked contrast and topography for the contrast\n",
    "evo.plot_roi(study=2, data=evokeds, tmin=-0.1, tmax=0.3, tmin_base=-0.1, tmax_base=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff70bf",
   "metadata": {},
   "source": [
    "### 4. Time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tfr representations for each condition\n",
    "tfr.compute_tfr(\n",
    "    study=2,\n",
    "    cond=\"prev_resp\",\n",
    "    tmin=-0.4,\n",
    "    tmax=0,\n",
    "    fmax=35,\n",
    "    fmin=3,\n",
    "    laplace=False,\n",
    "    induced=False,\n",
    "    mirror=True,\n",
    "    drop_bads=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356801e",
   "metadata": {},
   "source": [
    "#### stimulus probability contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abca9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tfr data for each condition for probability conds.\n",
    "tfr_a_cond, tfr_b_cond = tfr.load_tfr_conds(\n",
    "    studies=[1, 2],\n",
    "    cond=\"probability\",\n",
    "    cond_a_name=\"high_-0.7_0\",\n",
    "    cond_b_name=\"low_-0.7_0\",\n",
    "    cond_a_names=[\"high_prevhit_-0.7_0\", \"high_prevmiss_-0.7_0\", \"high_prevcr_-0.7_0\"],\n",
    "    cond_b_names=[\"low_prevhit_-0.7_0\", \"low_prevmiss_-0.7_0\", \"low_prevcr_-0.7_0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b1828",
   "metadata": {},
   "source": [
    "#### Qualitative checks for TFR (no stats yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot grand average per condition (no differences, Gabriel Curios comments, numbtouch symposium)\n",
    "\n",
    "# study 1\n",
    "high_study1 = np.array(tfr_a_cond[0])\n",
    "low_study1 = np.array(tfr_b_cond[0])\n",
    "\n",
    "# study 2\n",
    "high_study2 = np.array(tfr_a_cond[1])\n",
    "low_study2 = np.array(tfr_b_cond[1])\n",
    "\n",
    "# study 1: prevhits\n",
    "prevhit_highstudy1 = high_study1[:, 0]\n",
    "prevhit_lowstudy1 = low_study1[:, 0]\n",
    "\n",
    "# grand average over participants\n",
    "# study 1\n",
    "prevhit_highstudy1gra = mne.grand_average(list(prevhit_highstudy1))\n",
    "prevhit_lowstudy1gra = mne.grand_average(list(prevhit_lowstudy1))\n",
    "\n",
    "high_study2gra = mne.grand_average(list(high_study2))\n",
    "low_study2gra = mne.grand_average(list(low_study2))\n",
    "\n",
    "# plot grand average\n",
    "# study 1\n",
    "diff = mne.combine_evoked([prevhit_highstudy1gra, prevhit_lowstudy1gra], weights=[1, -1])\n",
    "diff.copy().crop(-0.4, 0).apply_baseline((-0.4, 0), mode=\"zscore\").plot(picks=[\"CP4\"])\n",
    "\n",
    "diff = mne.combine_evoked([high_study2gra, low_study2gra], weights=[1, -1])\n",
    "diff.copy().crop(-0.4, 0).apply_baseline((-0.4, 0), mode=\"zscore\").plot(picks=[\"CP4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of frequencies higher than 7 and smaller than 13\n",
    "freqs = tfr_a_cond[1][0].freqs\n",
    "freqs = np.array(freqs)\n",
    "# extract the indices of alpha frequencies (7-13 Hz)\n",
    "alpha = np.where((freqs > 7) & (freqs < 13))\n",
    "# extract the indices of beta frequencies (13-30 Hz)\n",
    "beta = np.where((freqs > 14) & (freqs < 26))\n",
    "# find index of channel CP4\n",
    "idx = tfr_a_cond[1][0].ch_names.index(\"CP4\")\n",
    "\n",
    "# extract the data for alpha and beta frequencies and channel CP4 for each participant\n",
    "# study 1\n",
    "prevhit_highstudy1_alpha = np.array([h_.crop(-0.4, 0).data[idx, alpha] for h_ in np.array(tfr_a_cond[0])[:, 1]])\n",
    "# now average over alpha frequencies\n",
    "prevhit_highstudy1_alpha = np.mean(np.squeeze(prevhit_highstudy1_alpha), axis=1)\n",
    "\n",
    "prevhit_lowstudy1_alpha = np.array([l_.crop(-0.4, 0).data[idx, alpha] for l_ in np.array(tfr_b_cond[0])[:, 1]])\n",
    "# now average over alpha frequencies\n",
    "prevhit_lowstudy1_alpha = np.mean(np.squeeze(prevhit_lowstudy1_alpha), axis=1)\n",
    "\n",
    "# study 2\n",
    "high_study2_alpha = np.array([h_.crop(-0.4, 0).data[idx, alpha] for h_ in np.array(tfr_a_cond[1])])\n",
    "# now average over alpha frequencies\n",
    "high_study2_alpha = np.mean(np.squeeze(high_study2_alpha), axis=1)\n",
    "\n",
    "low_study2_alpha = np.array([l_.crop(-0.4, 0).data[idx, alpha] for l_ in np.array(tfr_b_cond[1])])\n",
    "# now average over alpha frequencies\n",
    "low_study2_alpha = np.mean(np.squeeze(low_study2_alpha), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extract beta power and plot\n",
    "# study 1\n",
    "prevhit_highstudy1_beta = np.array([h_.crop(-0.4, 0).data[idx, beta] for h_ in np.array(tfr_a_cond[0])[:, 0]])\n",
    "prevhit_highstudy1_beta = np.mean(np.squeeze(prevhit_highstudy1_beta), axis=1)\n",
    "\n",
    "prevhit_lowstudy1_beta = np.array([l_.crop(-0.4, 0).data[idx, beta] for l_ in np.array(tfr_b_cond[0])[:, 0]])\n",
    "\n",
    "prevhit_lowstudy1_beta = np.mean(np.squeeze(prevhit_lowstudy1_beta), axis=1)\n",
    "\n",
    "# study 2\n",
    "high_study2_beta = np.array([h_.crop(-0.4, 0).data[idx, beta] for h_ in np.array(tfr_a_cond[1])])\n",
    "high_study2_beta = np.mean(np.squeeze(high_study2_beta), axis=1)\n",
    "\n",
    "low_study2_beta = np.array([l_.crop(-0.4, 0).data[idx, beta] for l_ in np.array(tfr_b_cond[1])])\n",
    "low_study2_beta = np.mean(np.squeeze(low_study2_beta), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now zscore the data over participants\n",
    "# study 1\n",
    "prevhit_highstudy1_alpha = (prevhit_highstudy1_alpha - np.mean(prevhit_highstudy1_alpha)) / np.std(\n",
    "    prevhit_highstudy1_alpha\n",
    ")\n",
    "prevhit_lowstudy1_alpha = (prevhit_lowstudy1_alpha - np.mean(prevhit_lowstudy1_alpha)) / np.std(\n",
    "    prevhit_lowstudy1_alpha\n",
    ")\n",
    "\n",
    "prevhit_highstudy1_beta = (prevhit_highstudy1_beta - np.mean(prevhit_highstudy1_beta)) / np.std(\n",
    "    prevhit_highstudy1_beta\n",
    ")\n",
    "prevhit_lowstudy1_beta = (prevhit_lowstudy1_beta - np.mean(prevhit_lowstudy1_beta)) / np.std(prevhit_lowstudy1_beta)\n",
    "\n",
    "# study 2\n",
    "high_study2_alpha = (high_study2_alpha - np.mean(high_study2_alpha)) / np.std(high_study2_alpha)\n",
    "low_study2_alpha = (low_study2_alpha - np.mean(low_study2_alpha)) / np.std(low_study2_alpha)\n",
    "\n",
    "high_study2_beta = (high_study2_beta - np.mean(high_study2_beta)) / np.std(high_study2_beta)\n",
    "low_study2_beta = (low_study2_beta - np.mean(low_study2_beta)) / np.std(low_study2_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the following variables from your previous code\n",
    "time = tfr_a_cond[1][0].crop(-0.4, 0).times\n",
    "uncorrected_alpha_level = params.alpha  # 0.05\n",
    "\n",
    "# Number of comparisons (number of time points)\n",
    "num_comparisons = len(time)\n",
    "\n",
    "# Bonferroni-corrected significance level\n",
    "alpha_level = uncorrected_alpha_level / num_comparisons\n",
    "\n",
    "# Create a figure with two rows and two columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Study 1 - Alpha power\n",
    "data_high_alpha = np.mean(prevhit_highstudy1_alpha, axis=0)\n",
    "data_low_alpha = np.mean(prevhit_lowstudy1_alpha, axis=0)\n",
    "axes[0, 0].plot(time, data_high_alpha, label=\"high_probability\", color=\"#ca0020ff\")\n",
    "axes[0, 0].plot(time, data_low_alpha, label=\"low_probability\", color=\"#0571b0ff\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xlabel(\"time (ms)\")\n",
    "axes[0, 0].set_ylabel(\"alpha power (z-scored)\")\n",
    "axes[0, 0].set_title(\"Study 1\")\n",
    "axes[0, 0].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"Stimulation Onset\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test for Study 1 - High vs Low Alpha\n",
    "_, p_value_alpha_study1 = wilcoxon(prevhit_highstudy1_alpha.flatten(), prevhit_lowstudy1_alpha.flatten())\n",
    "\n",
    "# Add significance marker if p-value is less than alpha\n",
    "if p_value_alpha_study1 < alpha_level:\n",
    "    axes[0, 0].text(0.5, 0.9, \"*\", color=\"red\", fontsize=12, ha=\"center\", va=\"center\", transform=axes[0, 0].transAxes)\n",
    "\n",
    "# Study 1 - Beta power\n",
    "data_high_beta = np.mean(prevhit_highstudy1_beta, axis=0)\n",
    "data_low_beta = np.mean(prevhit_lowstudy1_beta, axis=0)\n",
    "axes[1, 0].plot(time, data_high_beta, label=\"high_probability\", color=\"#ca0020ff\")\n",
    "axes[1, 0].plot(time, data_low_beta, label=\"low_probability\", color=\"#0571b0ff\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_xlabel(\"time (ms)\")\n",
    "axes[1, 0].set_ylabel(\"beta power (z-scored)\")\n",
    "axes[1, 0].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"Stimulation Onset\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test for Study 1 - High vs Low Beta\n",
    "_, p_value_beta_study1 = wilcoxon(prevhit_highstudy1_beta.flatten(), prevhit_lowstudy1_beta.flatten())\n",
    "\n",
    "# Add significance marker if p-value is less than alpha\n",
    "if p_value_beta_study1 < alpha_level:\n",
    "    axes[1, 0].text(0.5, 0.9, \"*\", color=\"red\", fontsize=12, ha=\"center\", va=\"center\", transform=axes[1, 0].transAxes)\n",
    "\n",
    "# Study 2 - Alpha power\n",
    "data_high_alpha_study2 = np.mean(high_study2_alpha, axis=0)\n",
    "data_low_alpha_study2 = np.mean(low_study2_alpha, axis=0)\n",
    "axes[0, 1].plot(time, data_high_alpha_study2, label=\"high_probability\", color=\"#ca0020ff\")\n",
    "axes[0, 1].plot(time, data_low_alpha_study2, label=\"low_probability\", color=\"#0571b0ff\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_xlabel(\"time (ms)\")\n",
    "axes[0, 1].set_ylabel(\"alpha power (z-scored)\")\n",
    "axes[0, 1].set_title(\"Study 2\")\n",
    "axes[0, 1].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"Stimulation Onset\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test for Study 2 - High vs Low Alpha\n",
    "_, p_value_alpha_study2 = wilcoxon(high_study2_alpha.flatten(), low_study2_alpha.flatten())\n",
    "\n",
    "# Add significance marker if p-value is less than alpha\n",
    "if p_value_alpha_study2 < alpha_level:\n",
    "    axes[0, 1].text(0.5, 0.9, \"*\", color=\"red\", fontsize=12, ha=\"center\", va=\"center\", transform=axes[0, 1].transAxes)\n",
    "\n",
    "# Study 2 - Beta power\n",
    "data_high_beta_study2 = np.mean(high_study2_beta, axis=0)\n",
    "data_low_beta_study2 = np.mean(low_study2_beta, axis=0)\n",
    "axes[1, 1].plot(time, data_high_beta_study2, label=\"high_probability\", color=\"#ca0020ff\")\n",
    "axes[1, 1].plot(time, data_low_beta_study2, label=\"low_probability\", color=\"#0571b0ff\")\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_xlabel(\"time (ms)\")\n",
    "axes[1, 1].set_ylabel(\"beta power (z-scored)\")\n",
    "# Add red line at stimulation onset\n",
    "axes[1, 1].axvline(x=0, color=\"red\", linestyle=\"--\", label=\"Stimulation Onset\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test for Study 2 - High vs Low Beta\n",
    "_, p_value_beta_study2 = wilcoxon(high_study2_beta.flatten(), low_study2_beta.flatten())\n",
    "\n",
    "# Add significance marker if p-value is less than alpha\n",
    "if p_value_beta_study2 < alpha_level:\n",
    "    axes[1, 1].text(0.5, 0.9, \"*\", color=\"red\", fontsize=12, ha=\"center\", va=\"center\", transform=axes[1, 1].transAxes)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure as SVG\n",
    "plt.savefig(f\"{save_dir_fig4_suppl}/suppl_fig_4.svg\", format=\"svg\", dpi=300)\n",
    "\n",
    "# Save the figure as PNG\n",
    "plt.savefig(f\"{save_dir_fig4_suppl}/suppl_fig_4.png\", format=\"png\", dpi=300)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = 1  # expecon 2, single trial cues\n",
    "\n",
    "# pick 10 random participants\n",
    "random_ids = random.sample(range(0, len(tfr_a_cond[1])), 5)\n",
    "\n",
    "# create figure with 3 rows and 5 columns\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15, 10))\n",
    "\n",
    "# now fill the figure with the plots\n",
    "for i, sid in enumerate(random_ids):\n",
    "    # plot tfr for each condition\n",
    "    tfr_a_cond[study][sid].copy().crop(-0.4, 0).plot(picks=[\"CP4\"], axes=axs[0, i], show=False)\n",
    "    tfr_b_cond[study][sid].crop(-0.4, 0).plot(picks=[\"CP4\"], axes=axs[1, i], show=False)\n",
    "\n",
    "    diff = tfr_a_cond[study][sid].copy().crop(-0.4, 0) - tfr_b_cond[study][sid].crop(-0.4, 0)\n",
    "    diff.plot(picks=[\"CP4\"], axes=axs[2, i], show=False)\n",
    "    # get rid of y label for every plot expcept the first one on the left\n",
    "    axs[0, i].set_ylabel(\"\")\n",
    "    axs[1, i].set_ylabel(\"\")\n",
    "    axs[2, i].set_ylabel(\"\")\n",
    "    # also remove x axis for each row except the last row\n",
    "    axs[0, i].set_xlabel(\"\")\n",
    "    axs[1, i].set_xlabel(\"\")\n",
    "    axs[2, i].set_xlabel(\"\")\n",
    "    # set title for each plot\n",
    "    axs[0, i].set_title(f\"ID {sid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = 0  # mini block design, study 1\n",
    "conds = [0, 1, 2]  # prev hit, prev miss, prev cr\n",
    "\n",
    "# pick 10 random participants\n",
    "random_ids = random.sample(range(0, len(tfr_a_cond[0])), 5)\n",
    "\n",
    "for c in conds:\n",
    "    # create figure with 3 rows and 5 columns\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(15, 10))\n",
    "    # now fill the figure with the plots\n",
    "    for i, sid in enumerate(random_ids):\n",
    "        # plot tfr for each condition\n",
    "        tfr_a_cond[study][sid][c].copy().crop(-0.4, 0).plot(picks=[\"CP4\"], axes=axs[0, i], show=False)\n",
    "        tfr_b_cond[study][sid][c].crop(-0.4, 0).plot(picks=[\"CP4\"], axes=axs[1, i], show=False)\n",
    "\n",
    "        diff = tfr_a_cond[study][sid][c].copy().crop(-0.4, 0) - tfr_b_cond[study][sid][c].crop(-0.4, 0)\n",
    "        diff.plot(picks=[\"CP4\"], axes=axs[2, i], show=False)\n",
    "        # get rid of y label for every plot expcept the first one on the left\n",
    "        axs[0, i].set_ylabel(\"\")\n",
    "        axs[1, i].set_ylabel(\"\")\n",
    "        axs[2, i].set_ylabel(\"\")\n",
    "        # also remove x axis for each row except the last row\n",
    "        axs[0, i].set_xlabel(\"\")\n",
    "        axs[1, i].set_xlabel(\"\")\n",
    "        axs[2, i].set_xlabel(\"\")\n",
    "        # set title for each plot\n",
    "        axs[0, i].set_title(f\"ID {sid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run-cluster-based permutation tests for the conditions contrast\n",
    "# and plot sign. cluster\n",
    "tfr.plot_tfr_cluster_test_output(\n",
    "    cond=\"probability\",\n",
    "    tfr_a_cond=tfr_a_cond,\n",
    "    tfr_b_cond=tfr_b_cond,\n",
    "    threed_test=False,\n",
    "    cond_a_name=\"high\",\n",
    "    cond_b_name=\"low\",\n",
    "    channel_names=[\"CP4\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dddc43",
   "metadata": {},
   "source": [
    "previous response contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tfr data for each condition for prev_resp conds.\n",
    "tfr_a_cond, tfr_b_cond = tfr.load_tfr_conds(\n",
    "    studies=[1, 2],\n",
    "    cond=\"prev_resp\",\n",
    "    cond_a_name=\"prevyesresp_highprob_stim_-0.7_0\",\n",
    "    cond_b_name=\"prevnoresp_highprob_stim_-0.7_0\",\n",
    "    cond_a_names=[\"prevyesresp_samecue_lowprob_-0.7_0\", \"prevyesresp_samecue_highprob_-0.7_0\"],\n",
    "    cond_b_names=[\"prevnoresp_samecue_lowprob_-0.7_0\", \"prevnoresp_samecue_highprob_-0.7_0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cluster based permutation tests for the conditions contrasts\n",
    "# and plot sign. cluster\n",
    "tfr.plot_tfr_cluster_test_output(\n",
    "    cond=\"prev_resp\",\n",
    "    tfr_a_cond=tfr_a_cond,\n",
    "    tfr_b_cond=tfr_b_cond,\n",
    "    threed_test=False,\n",
    "    cond_a_name=\"prevyesresp\",\n",
    "    cond_b_name=\"prevnoresp\",\n",
    "    channel_names=[\"CP4\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8a728",
   "metadata": {},
   "source": [
    "### 5. Source reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run source reconstruction for each condition\n",
    "source_reco.run_source_reco(\n",
    "    study=1,\n",
    "    cond=\"prev_resp\",\n",
    "    mirror=False,\n",
    "    dics=True,\n",
    "    fmin=15,\n",
    "    fmax=25,\n",
    "    tmin=-0.7,\n",
    "    tmax=-0.1,\n",
    "    drop_bads=True,\n",
    "    plot_alignment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot source contrast (grand average over all participants)\n",
    "# opens plots in separate windows\n",
    "source_reco.plot_grand_average_source_contrast(\n",
    "    study=1, cond=\"probability\", method=\"beamformer\", save_plots=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaefaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run source localization for each epoch based on filter from contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf35dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_reco.run_source_reco_per_trial(study=2, fmin=15, fmax=25, tmin=-0.7, tmax=-0.1, drop_bads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0022c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6 correlation between source power and behavioral outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_source_behav_correlation.plot_correlation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expecon_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
